{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R7_InternalLab_Questions_FMNIST_Simple_CNN_CIFAR_DATA_Augment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyfMmMnPJjvn",
        "colab_type": "text"
      },
      "source": [
        "## Train a simple convnet on the Fashion MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjcGOJhcJjvp",
        "colab_type": "text"
      },
      "source": [
        "In this, we will see how to deal with image data and train a convnet for image classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR0Pl2XjJjvq",
        "colab_type": "text"
      },
      "source": [
        "### Load the  `fashion_mnist`  dataset\n",
        "\n",
        "** Use keras.datasets to load the dataset **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr75v_UYJjvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "030zI1n0VD3-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5QEpIV8UWw6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.reset_default_graph()\n",
        "tf.set_random_seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTI42-0qJjvw",
        "colab_type": "text"
      },
      "source": [
        "### Find no.of samples are there in training and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2sf67VoJjvx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Number of samples available in training dataset\n",
        "print('Train: X=%s, y=%s' % (x_train.shape, y_train.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zewyDcBlJjv1",
        "colab_type": "code",
        "outputId": "27d137f2-bf13-4869-e426-5d01042dc572",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Number of samples available in test dataset\n",
        "print('Train: X=%s, y=%s' % (x_test.shape, y_test.shape))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: X=(10000, 28, 28), y=(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WytT2eRnJjv4",
        "colab_type": "text"
      },
      "source": [
        "### Find dimensions of an image in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XycQGBSGJjv5",
        "colab_type": "code",
        "outputId": "9ed089db-59e2-4969-eceb-d811ff44e18f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Find the dimension of first data from training\n",
        "x_train[0,:,:].shape"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jtdZ7RqJjv8",
        "colab_type": "text"
      },
      "source": [
        "### Convert train and test labels to one hot vectors\n",
        "\n",
        "** check `keras.utils.to_categorical()` **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAD3q5I6Jjv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one hot encode training values\n",
        "y_train = tf.keras.utils.to_categorical(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgHSCXy3JjwA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one hot encode test values\n",
        "y_test = tf.keras.utils.to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO5BRBzBJjwD",
        "colab_type": "text"
      },
      "source": [
        "### Normalize both the train and test image data from 0-255 to 0-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fUQpMHxJjwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First convert train and test data to float\n",
        "TrainX = x_train.astype('float32')\n",
        "TestX = x_test.astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Okwo_SB5JjwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now convert the data to 0-1\n",
        "TrainX = TrainX/255.0\n",
        "TestX = TestX/255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da5-DwgrJjwM",
        "colab_type": "text"
      },
      "source": [
        "### Reshape the data from 28x28 to 28x28x1 to match input dimensions in Conv2D layer in keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPGVQ-JJJjwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TrainX = TrainX.reshape((TrainX.shape[0], 28, 28, 1))\n",
        "TestX = TestX.reshape((TestX.shape[0], 28, 28, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFRRTJq8JjwQ",
        "colab_type": "text"
      },
      "source": [
        "### Import the necessary layers from keras to build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blf6zk9ZAGpB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define some parameters\n",
        "img_size = 28\n",
        "img_depth = 1\n",
        "batchsize = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5fgwiSaVBBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWTZYnKSJjwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initialize model, reshape & normalize data\n",
        "model = tf.keras.models.Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C18AoS7eJjwU",
        "colab_type": "text"
      },
      "source": [
        "### Build a model \n",
        "\n",
        "** with 2 Conv layers having `32 3x3 filters` in both convolutions with `relu activations` and `flatten` before passing the feature map into 2 fully connected layers (or Dense Layers) having 128 and 10 neurons with `relu` and `softmax` activations respectively. Now, using `categorical_crossentropy` loss with `adam` optimizer train the model with early stopping `patience=5` and no.of `epochs=10`. **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DORCLgSwJjwV",
        "colab_type": "code",
        "outputId": "98c0dd03-553f-4a3b-aecf-070583eb9765",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu'))\n",
        "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu'))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(TrainX,y_train,          \n",
        "          validation_data=(TestX,y_test),\n",
        "          epochs=10,\n",
        "          batch_size = 32)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 8s 133us/sample - loss: 0.3754 - acc: 0.8654 - val_loss: 0.2956 - val_acc: 0.8910\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.2318 - acc: 0.9146 - val_loss: 0.2512 - val_acc: 0.9111\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.1698 - acc: 0.9357 - val_loss: 0.2457 - val_acc: 0.9126\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.1172 - acc: 0.9567 - val_loss: 0.2905 - val_acc: 0.9093\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.0782 - acc: 0.9706 - val_loss: 0.3290 - val_acc: 0.9092\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.0527 - acc: 0.9810 - val_loss: 0.3658 - val_acc: 0.9162\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.0385 - acc: 0.9867 - val_loss: 0.4137 - val_acc: 0.9123\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.0269 - acc: 0.9898 - val_loss: 0.4862 - val_acc: 0.9142\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.0227 - acc: 0.9923 - val_loss: 0.5277 - val_acc: 0.9137\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.0204 - acc: 0.9930 - val_loss: 0.5530 - val_acc: 0.9082\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd359533a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUZZ9ncyDOAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from tf.keras.callbacks import EarlyStopping\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto', baseline=None, restore_best_weights=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-Yj8EaqCLSy",
        "colab_type": "code",
        "outputId": "c5b975f3-74b1-46b2-d33d-bd758499623c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "\n",
        "model.fit(TrainX,y_train,          \n",
        "          validation_data=(TestX,y_test),\n",
        "          epochs=10,\n",
        "          batch_size = 32,\n",
        "          callbacks= [es])"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 8s 133us/sample - loss: 0.0169 - acc: 0.9941 - val_loss: 0.5644 - val_acc: 0.9104\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.0163 - acc: 0.9944 - val_loss: 0.6883 - val_acc: 0.9086\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.0143 - acc: 0.9952 - val_loss: 0.6160 - val_acc: 0.9090\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.0138 - acc: 0.9950 - val_loss: 0.6743 - val_acc: 0.9122\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.0123 - acc: 0.9959 - val_loss: 0.6535 - val_acc: 0.9129\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.0107 - acc: 0.9964 - val_loss: 0.7649 - val_acc: 0.9127\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd3595c8198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju69vKdIJjwX",
        "colab_type": "text"
      },
      "source": [
        "### Now, to the above model add `max` pooling layer of `filter size 2x2` and `dropout` layer with `p=0.25` after the 2 conv layers and run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2hAP94vJjwY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "3f1702fa-6c5a-4b0e-ea6b-2d283486d411"
      },
      "source": [
        "#Initialize model, reshape & normalize data\n",
        "model = tf.keras.models.Sequential()\n",
        "# Define input layer\n",
        "model.add(tf.keras.layers.BatchNormalization(input_shape=(img_size,img_size,1,)))\n",
        "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu'))\n",
        "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization_1 (Batch (None, 28, 28, 1)         4         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 24, 24, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               589952    \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 600,814\n",
            "Trainable params: 600,812\n",
            "Non-trainable params: 2\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTeXUpNMP3H0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "ca6e4ef6-63d8-4cbd-a50a-2e0c439f37f1"
      },
      "source": [
        "model.fit(TrainX,y_train,          \n",
        "          validation_data=(TestX,y_test),\n",
        "          epochs=10,\n",
        "          batch_size = 32) "
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 8s 132us/sample - loss: 0.3686 - acc: 0.8673 - val_loss: 0.2819 - val_acc: 0.8961\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.2429 - acc: 0.9107 - val_loss: 0.2413 - val_acc: 0.9115\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 8s 125us/sample - loss: 0.1962 - acc: 0.9260 - val_loss: 0.2253 - val_acc: 0.9195\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.1615 - acc: 0.9391 - val_loss: 0.2265 - val_acc: 0.9216\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.1352 - acc: 0.9490 - val_loss: 0.2305 - val_acc: 0.9256\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.1122 - acc: 0.9566 - val_loss: 0.2497 - val_acc: 0.9228\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.0945 - acc: 0.9644 - val_loss: 0.2537 - val_acc: 0.9234\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0836 - acc: 0.9687 - val_loss: 0.2913 - val_acc: 0.9214\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.0747 - acc: 0.9713 - val_loss: 0.2932 - val_acc: 0.9223\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0639 - acc: 0.9763 - val_loss: 0.2981 - val_acc: 0.9259\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd3590fce10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGTA3bfEJjwa",
        "colab_type": "text"
      },
      "source": [
        "### Now, to the above model, lets add Data Augmentation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6gX8n5SJjwb",
        "colab_type": "text"
      },
      "source": [
        "### Import the ImageDataGenrator from keras and fit the training images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cbz4uHBuJjwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=20,\n",
        "                                                                   width_shift_range=0.2,\n",
        "                                                                   height_shift_range=0.2,\n",
        "                                                                   horizontal_flip=True)\n",
        "datagen.fit(TrainX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl-8dOo7Jjwf",
        "colab_type": "text"
      },
      "source": [
        "#### Showing 5 versions of the first image in training dataset using image datagenerator.flow()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "DpI1_McYJjwg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "fb3d591c-37b4-495e-b135-bb7ab18fe044"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "gen = datagen.flow(TrainX[0:1], batch_size=1)\n",
        "for i in range(1, 6):\n",
        "    plt.subplot(1,5,i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(gen.next().squeeze(), cmap='gray')\n",
        "    plt.plot()\n",
        "plt.show()"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAABcCAYAAABz9T77AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFv5JREFUeJztnWmsXdP7xz9V/ZlnRamp5lnRGGOq\naInpBRHEkJjeInglkYgEbyS8amKKCIIQNIYYYhbzrGaqSk1FzfP5v/D/3LXOc+9p77n39vbs9vm8\n2fecu8/ea6+99l7f51nPetaYVqtFkiRJ0lyWW9IFSJIkSYZHvsiTJEkaTr7IkyRJGk6+yJMkSRpO\nvsiTJEkaTr7IkyRJGk6+yJMkSRpOvsiTJEkaTr7IkyRJGs7yo3myMWPGLBPTSFut1pjB7pt10p9x\n48a1AKZOnQrAOeecA8Bdd90FwNprrw3AE088AcDYsWMBWH750px/+eUXALbffnuPCcB3333Xdox/\n/vkHgIceegiAL774opvLGhbd1An0Rluxrpdb7j8N+Ndff7X93+///ffffr/1f/Hz//73P6DcvwUL\nFuTzE1hUW0lFniRJ0nBGVZEni4cxY8a0bQdSQ03i77//BmCXXXYBYJtttgFg//33B+DLL78E4IQT\nTmj7rLID2GKLLQD4/fffAfjqq68A2HXXXQHYcMMNgaIwP//8cwDmz58PwJ9//glA5iL6Dy2anXba\nqe3zt99+C5R6/vHHHwH4448/+n5rXdouV155ZaBYS3vvvTcAc+fOXXwXsJSTijxJkqThpCLvcTqp\nbT9DUZ+rrroqAB988AEAv/76K9BcVbnvvvsCsMEGGwCwzz77ADBr1iygXN8OO+wAFDUI8PPPPwOw\nySabADBhwgQAxo8fDxQf+W+//QbARhttBBQlqb9W62BZJSrx448/Higq2zEF69f6fPvtt/uOYZv1\nnqjeVeJ+PvHEExfTVSz9pCJPkiRpOKnIlzAq6zjar4qOW327kyZN6juGilxf8rvvvgvAgw8+CMA3\n33zTds5eV+innHIKUJS2dbTKKqsAMGXKFKDUmaq5vi4VtcrRz9avn1WDKklp+jjDcHHswDrdcsst\nAZg2bRoACxYsAIoif++994DSFrfaaqu+Y82ZMwcoES5aRd63ddZZB4A99thjcVzKIrEdxTbTJFKR\nJ0mSNJxU5EsYfZCdVIAj/PqHDzroIABWWGGFvn3WWGMNoKgm/b0ffvghUCILpNcV+c477wzA7Nmz\ngaLIrQvVsipaRWVdQolgWWmlldp+o9I0fnyttdZqO7aq3zj0ZRXrPKpm68nPjjVsvfXWQLFwaitw\n4sSJQLknRhDZhrfddlsAVl999WGXt1Pbto24X/382AaMonn55ZcB+P777xd6zF4iFXmSJEnDWeoU\n+YorrggUhaB/7ocffmjbb2Ez0EYT/cGvvPIK0H9G4uTJkwHYeOONgaJmavRHuo+qUj/6888/DxQV\n2usYy/3RRx8BsNtuuwHFalFVq6pU5rVysp5sD1ot3nePoUqcPn06ADfccAOwaIW3tKMSV4Fb13E2\n5vrrr9/2u+hTh/7tbrvttmvbV1TG3RDHPmI5ojWntVqPMa277rpAedZ23313AG655RagvEN65Z0x\nEKnIkyRJGk5jFXnsHY1jPfzww4HSy77wwgsAzJs3D4BPP/0UKL68SB2fLYtTlamenaVouYyRVoVq\nUagWjI+G/rHma665JlBmQr7xxhtt217H8h955JFA/3ulL9zvY1QLlFh6Y+tVbip024/jB0b4yLKq\nxCOrrbYaUGbE6hOPUS1uVer1GIOKPMbku6/HckynjnhZFM7+/eyzz4Dy3NgWbEtauI411T5yffNa\n8T/99BNQYuE9diryJEmSZLHReEWuEjC2+JhjjgFKr6kis6c2n8Pjjz8OlBwbsZetlbmKQUayRzZ2\nVgWpgvB7lbfqRTVal8nvol/XCBeP3RRFfsQRRwBFDWqNqKK8Xj+r9OpYcP2t1ptK3H39rWrRTIrJ\nf9iWHGswSsWZr9ajz6HW0ddffw2U5y7+DeVe+Bx5P1XC3XDggQe2nVcLS9+9ce2bbbZZW/lrv71q\nXf+51+JvfZ56eZZvKvIkSZKGky/yJEmShtNY10o0cxwEdDKJCXo0/V599VWguGA0o15//XUAPvnk\nE6AMitahUO6r2ebgR5zEM5QBskMPPRSAPffcs628uk7iFP7oRqnLEZP862po2pRjUw04DTwOqHmd\n0cWlyQ7909j62+gm837rYkv+I7blZ599FihuCN0l1q/3RNdFXc/RLWN7NCTQ79dbb72uy6kLxdDb\nOPHHNmF5TP7lJKV6X/dxEtlee+0FlAFV3xW9SCryJEmShtNYRS6GExlqp2JVMTgxwQkhKrDYC9uj\nO+BimBX0H5xxWTBVv98PZcJNTNgTp5/HYzpoWw8MaT0YcuUAn1uVT1Pw2i234WExDWq0WmqFbr3F\niSx+r+pyIHXTTTcFysDw0rJIx0jx2muvAaXOo5VnfdoW62X3rHO/iwPQnUKBB8PBBx8MlPtmm1Fx\nq/J9L7itl52L7UgOOOAAAN555x2gKPJenCyWijxJkqThNE6Rx97woosuAkrK0zjxQ6WgqlMx2FPr\nS3UarhMZah+859Rn5pR3zxUXpO0GlylTTasALXec9KKiqEPttDbcR7Xkvqa+NZxPZdurqjNOirLc\n+mFNmap/1HvqdUF/f2dsN6rCm2++GSg+8l6e9DGaxPBeF632uYmhgtav96JWty74YZ261Tc+lOdG\nfO4N0+2U/jleT31/fdbdWnbbU0zv0UtKXFKRJ0mSNJzGKfLYG0YFZS+qb1RlpuJVpeoD13+nunMC\nRL14rKPWfqe/UMU4HJwGfMghhwBFvUTfuNeppVGP8MdrdV/V6I477th2Hc888wwwcDqCXsB7qQJX\nDTpZyqRLjoNEawXKvYmRPHFhiTPOOAOAe++9t22/mO52WSOOKWgVvfXWW0CJLPL/UWUPZNHG9qnl\n6LHrxbMHixa074WYDsDPlsFIqNp6M6rGd0SceNYEUpEnSZI0nMYpcrGH1T+swlIR2FO71aesko3K\n3iRbJt+q/+/iv08++WTbsUYC1aVJ7FUBqmnPpbJULQwUc+u1R6Wt+nAb/YSL8guPdiIxUSFZB9aR\nCl3rRD9pfV9Ue9aJ5fWY1qe+1VNPPRWA+++/H+i/PN6yQhw3sd6ipWi9Wo+qbT/XkSi2WbeOcWhR\nef/0RXcTT+5Sc44DWW7VfVxMOy4POBD+xvbl+JrHjFZeL/jMU5EnSZI0nJ5W5HFWIxRF4AKu9sSq\nsZjMRxXqrExnaTrqHuOM7W1r/5gJeWLkS/QPDiXSYfPNNwdK9EqnlJ9xxpoKCRY9Mu/CDBdccAEA\n55xzDlBUq/7kWP7o06yVx3CueVFYHs8bZ7Wq2ExJ/NJLLwGlLqGoKe+n7eT9998HSvtxe/rpp7f9\nzkUFbCcDtUVY+nzoMdpDjO7SgnTxj+j/tj1o4db/0xcefeM+X0OZ4elzEtPqel/i/dIKqNPYRp+4\nv3FfZ4M7q/XNN99sO1cq8iRJkmTY9LQij0oTip/qpJNOAor/WsVtr6oysLdVIagg6pln0F9R1D32\nY489BpSoiZj4fjg9cpz1poKMCjDGiNcz69zHMlse/ZSqFuPgb7vtNqBEr5jSd9asWUB/68Zz1eqz\nU9rfkVAnKh7HP6Il5PiBkUamoH3uuef6jqFy9DePPvpo2+cYoaCav+SSS4CyyIBLv+nXjRbfQDMY\ne0GhdSK2q+gLFxdEPu2004D+i3xYf/q1PU6MwYYSFaIF5exqFa/3Mz6Tg0EL2/M5szNGnPhcec56\nEZJoWcfvzcOk5RDVfi/M9ExFniRJ0nBGVZF3ilvu1JPFkXAovaAzMVWLKvXYO6rmVJn64aI/zM/2\ntrXi1U+qYjV6olOmwm6wnKp9FYVKx8UgVC1aA3WdqCSMkY1+fpWO12ZeEZPtH3fccUBRwvqcVSAq\nKK8bSjSQ/mz3GYmInpjNMeZY0YeqlXX22WcD8OKLL/Ydw+gTvzNeXKWtmveaPLZbc/h4bx9++GGg\nZNE0qiVGMEBvKLSaOhNhJyXuPi5o4piBuUxsf95vx3T0c7utla44LqHVbGSY1tFwsnN6Xu+jFlOs\n+/gM1LM141iM+1gnth1zrsyYMQNYdJTXwnIBdbKEhkoq8iRJkoYzZjRVw9ixY1vQeeTfstiDRZUN\nJZuhMd0qophfJB5L3M//xxFr1XetYuy9L7zwQgAeeOCBhV5nq9UatDSfN29eC4rSUVFEX5/XoZKs\nla95QoxkiUpcVe9svJiT22Nbl0ZuuB2ojUQr5ZprrgHKeEKkmzp57rnnWlDqQr9m9E16nfpga7+o\nKl7VHucVuK9KTsXpOTotJ6cyv/322wF45JFH+pV/sIq8mzr5/+MO+2G1bCrZSZMmATB58mQADjvs\nMKDMAvb6o+WrRXLttde27a9lqT8cSjtU3evXtq5tt7apKVOmDLpefvvttxb0n0MRLXDL7Tnr8Z44\n3hGtcq0Mn1EXdJ85cyZQ2oQWrCzMQo/vp+G2lVTkSZIkDWdUfeTRHxfVsN/rO9t7772BsooOlJWA\n7C31C8c8Dfaqqkx725ixMEZ4SL3ajIrPKIqRJFojKggVhd/rk1RB6t+GotKNlVbhGJ1i/aqInBmp\nOo0ZI62bmJ2uVryOPRhj6776Q+OIfjd4rZ7D8qnM46xNZ/epBqGoKK8xrk7j/Y75yVWLsY68D0cd\ndRRQ2qR5dwAuvfTStu+W1GK9C1N5Xp9RKOb4ca6Bz4v1EldYsg0Y5XPFFVcAcPnll7ft73EBdt11\nV6Aobp9ZY9E75cUZDJbT5993iudSJTuD1zZSn0vrzd/E/DKilezaB46jnHXWWUBZp8B8NFolts96\njMnzp488SZIkAUbZR3700Ue3oKgfe7w4S3O//fYDyuj2wnpqy68fO/bM0c9rb2uUhT205xpIRfnd\njTfeCMD555+/0Ovsxvc5Z86cVl2+mPlPVKWq7VdeeaXvf6pg60BF60y0c889FygqU1Wq6lfRmxEy\nKiSvv7Zaok/SY1933XUDXudNN9006DoZP358C8oKLVoSrreoMrIdWWcDZdxTxcexE69dFWY7sR34\n+6hurRMtjrpOHCdQmS+KxeUjt2xGOJ133nl9/5s6dSpQnr1omcRcP7YVfeLxeYrZRD1ebb15DBWp\nbSdGh2j97LfffoOul/nz57fq34oWmeeO6xLU+1sulblzU8xMahswWsryeo0xv5PYxjyuFgiULKuO\nt7kmaszzLukjT5IkWcoZVR/51VdfDfSffelWJWhvH31W9d8qQPd1Jpor3Ee/r8o7ZgKM0QoDxYaq\n8vUvjiQxV4fnV0l4HV6nURjHHntsv2OpmlQGKgt7f9VSzAdtTL4Kwv/HSJpa8cY4fM+tNSBDsfiM\nN77zzjvbtkZYRKXuva9VYGwntgP3ietGWhdz584F+o+peF/8vXVRx0277mvM2jjaOTks6/Tp0wE4\n6KCD+v7nOI/lj+NUMUugajW2DZ8b6zFacXUuIP/2t/7GeooZFodCbNMey3JHda0XAIp1oh/9qaee\nAuDBBx8E4OSTT277TZx7YPmt2xgVNlD0ne3TeQ0+o64L2i2pyJMkSRrOqCrymM8krpEX1VFUpVD8\nVI5Gu7KLCtV4WEfG9RubL0F/lgrdsni8uKJQff7FkelP9enWa45+OOtG9WAPDsXvp0qy7Fo0+pRV\nX9FH6WfLECMX4vqn0F+tq8itZxlJFfrxxx+3bc2DYsTF0Ucf3bev7cGII62UmGdcteRWlaWiizMW\n/b91WltU3hPzAGnpxHKPdDuK/nzL7LyBOm+Q1x/z8sQcLF6Xlmtsj3HugdtoVUN7BBj0V82WyVw5\nWlyDYaDcSPX5jYCzHXhPnL0MJapk9uzZQLHiXA9YpR5nM1vPju3FSJ/ocRhojMmIHq0m30s+V4Nt\nK6nIkyRJGs6oKnJ7shhREkfK7Y3sKeueTIUQV9a56qqrgNJ7GomhX8vv9THHPC4DxUqLvacKwnJ2\nWrG7G4yesbf32lUSKj/L6/XXs2P9bcz9oiUR1Yq9vPUfV1eKWQ/jLLn6N5Zfy+ijjz4a/MWPEEbw\n1JE8F198MQBnnnkmAMcccwwAhx9+OFBUoG1M33hUnKpsozKsYy2+WjE9/fTTQGkf+kydD7HvvvsC\nRfl1S4zNt41PnDgRKD56285A6796fbYZj+U9j3n6bSNeS/Rnx/GT6PeG0n7M5aPyNg9OHYsPcNll\nly2yLsT7EOeNxIyg3hOtFC13KO8X24JjS76vtNZjXv44HhQjgeKckPqZjXM1rGfP3e38i1TkSZIk\nDSdf5EmSJA1nibhW3EbT3wEnByg1/+qBR00/XQxOEXcpKk0+XSpx2rnEJdU6hZtB/yRehsHF6fVD\nca041b6evlsfWxzQlIGWXYsDT5pt1nesgzjoHFOAaobHRQSghEndcccdQJmW3GuYpsDERqZ4cMFf\nk0Q5wOZgWBzstC1qNnu/7rrrrr5zOZgZUxLHCUyaz91iGXWheD9jygLdQbqLdCdBcUX4zNneHeCL\nA6ce0//bFnRR6saxLPfccw9QpqtDSaRmeUYS75fvg+gS8pl1YpiTcrwnUK7JyWDeY+tAt5rPVUxt\nYd24dT/P7blq16TltZzWjdtuU1ykIk+SJGk4o6rIo4KN01Fj4Ly9VT1Yp6qJCwPbm3YKBYoDdn52\nv6i661C7OPnBqe8xvGgoYWWGODl4q2KM57YHj6kG6vNGlaWSsK5iyKV1F5d2i4M8psG9/vrr+85p\n+trIUJJkLU5U1m4d0HJgUkWtYjMczPugkvfeq3ZdZGCgxTa8D6pV612rqlaD3eDgps9NXAzDtu1n\n1fett97adwzVeVxs3LLFha8N99XCta0Yvqfydqr5hx9+OKRrGy5xoN97oNqOz7l1U/8dl4GM75oY\njqvFah1a7zG8MqaFhlLfLlTi1uCBVORJkiTLGKOaNOvZZ59tQf9FgeOEk+jfGoioKKJ/t9OU+5j8\nKCa2idNtoSgrw6defvlloL8/Ua688spBy9Jx48a1LbYRl4VyG33m3WA9aq1Yvyr2OI3d0DwXrBgJ\nukkQNRILKHRLVF1incQ0x0NBJW57mjt3blfmy4EHHtj2/GgBRKtDhWlbrn3yhuFqcfhZBTtt2jSg\n+J5ddNop7iZ3Uo06AUwrYSQmO3XTVm655ZYWlLYtMSW2KnugFL/xnRAXlojvyPhMxneQ5/B9pkVW\nLwbjYuB33303UEIwaz96TSbNSpIkWcoZVUU+Y8aMFpREMXH5JcsSF0NdGHHqcIw+6YQ9n0rcz/a2\ndaSM5bzvvvuAklQnnsvtzJkze1p9Lgl6XZEPlcEs57WQ/3elyCdMmNCCorz1Z3dDp0UnHGNShRrd\nodWm2hxOYqvB0k29HHDAAS0oYxtaPT6/bmNkXB3BpWJWQWul+FujhOL7KEaJudU6McrrpptuAoo1\nA8WScVLRoiyZf//9NxV5kiTJ0syoKvKJEye2oEyXdqkkezxjU+0JjSSoR3vtWWOsuX7BTstGRR90\nXPLL71UitfLQV2yMrFEcnVha1edwWBbrpNPiFNV2RBeWGEyEw2g+70Ol19qKcz0cN3MBeMeWYmI2\nU2mLkSjuD93fh/SRJ0mSLOWMqiLv1Hsao6qfTn+RsZb1SG5cwDUmyI8LBsSZXvH7GHfqce1FoSjy\nTsswRXpNUfQCWSeFKjJpSIp8UUq/6fRqW7G+4wzpuJC71v5Ikoo8SZJkKWdUFXmSJEky8qQiT5Ik\naTj5Ik+SJGk4+SJPkiRpOPkiT5IkaTj5Ik+SJGk4+SJPkiRpOPkiT5IkaTj5Ik+SJGk4+SJPkiRp\nOPkiT5IkaTj5Ik+SJGk4+SJPkiRpOPkiT5IkaTj5Ik+SJGk4+SJPkiRpOPkiT5IkaTj5Ik+SJGk4\n+SJPkiRpOPkiT5IkaTj5Ik+SJGk4+SJPkiRpOPkiT5IkaTj5Ik+SJGk4/weAywVFmMX08AAAAABJ\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmPl5yE8Jjwm",
        "colab_type": "text"
      },
      "source": [
        "### Run the above model using fit_generator()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44ZnDdJYJjwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "img_generator= tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=20,\n",
        "                                                                   width_shift_range=0.2,\n",
        "                                                                   height_shift_range=0.2,\n",
        "                                                                   horizontal_flip=True)  \n",
        "img_generator.fit(TrainX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_it9r5HXx02",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "e37bd0da-cab1-46d9-931a-d45f4771bfbd"
      },
      "source": [
        "#Initialize model, reshape & normalize data\n",
        "model = tf.keras.models.Sequential()\n",
        "# Define input layer\n",
        "model.add(tf.keras.layers.BatchNormalization(input_shape=(img_size,img_size,1,)))\n",
        "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu'))\n",
        "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization_2 (Batch (None, 28, 28, 1)         4         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 24, 24, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 128)               589952    \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 600,814\n",
            "Trainable params: 600,812\n",
            "Non-trainable params: 2\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi82hQBlYH1H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4295acff-78fc-400b-cd60-231d79ddbe70"
      },
      "source": [
        "model.fit_generator(img_generator.flow(TrainX, y_train, batch_size = 32), \n",
        "                          epochs=50,\n",
        "                          steps_per_epoch= TrainX.shape[0]//batchsize,\n",
        "                          validation_data=(TestX, y_test),\n",
        "                          validation_steps = TestX.shape[0]//batchsize)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.7972 - acc: 0.7026 - val_loss: 0.6096 - val_acc: 0.7618\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.6016 - acc: 0.7735 - val_loss: 0.5138 - val_acc: 0.8022\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.5391 - acc: 0.7981 - val_loss: 0.4494 - val_acc: 0.8340\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.4985 - acc: 0.8145 - val_loss: 0.4886 - val_acc: 0.8177\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.4797 - acc: 0.8233 - val_loss: 0.3973 - val_acc: 0.8569\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.4598 - acc: 0.8286 - val_loss: 0.4206 - val_acc: 0.8454\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.4474 - acc: 0.8344 - val_loss: 0.4112 - val_acc: 0.8505\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.4367 - acc: 0.8406 - val_loss: 0.3569 - val_acc: 0.8720\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.4250 - acc: 0.8439 - val_loss: 0.3544 - val_acc: 0.8753\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.4175 - acc: 0.8459 - val_loss: 0.3564 - val_acc: 0.8728\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.4097 - acc: 0.8486 - val_loss: 0.4098 - val_acc: 0.8615\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.4060 - acc: 0.8507 - val_loss: 0.3374 - val_acc: 0.8819\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.3981 - acc: 0.8537 - val_loss: 0.3334 - val_acc: 0.8773\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.3963 - acc: 0.8529 - val_loss: 0.3413 - val_acc: 0.8784\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.3889 - acc: 0.8570 - val_loss: 0.3457 - val_acc: 0.8764\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.3849 - acc: 0.8584 - val_loss: 0.3175 - val_acc: 0.8866\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.3810 - acc: 0.8604 - val_loss: 0.3438 - val_acc: 0.8780\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.3788 - acc: 0.8616 - val_loss: 0.3275 - val_acc: 0.8794\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.3786 - acc: 0.8609 - val_loss: 0.3281 - val_acc: 0.8834\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.3725 - acc: 0.8621 - val_loss: 0.3355 - val_acc: 0.8801\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.3675 - acc: 0.8655 - val_loss: 0.3167 - val_acc: 0.8863\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.3693 - acc: 0.8626 - val_loss: 0.3192 - val_acc: 0.8866\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.3605 - acc: 0.8678 - val_loss: 0.3154 - val_acc: 0.8884\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.3627 - acc: 0.8665 - val_loss: 0.3278 - val_acc: 0.8833\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.3563 - acc: 0.8678 - val_loss: 0.3083 - val_acc: 0.8913\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.3589 - acc: 0.8676 - val_loss: 0.3095 - val_acc: 0.8914\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.3554 - acc: 0.8687 - val_loss: 0.3206 - val_acc: 0.8867\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.3531 - acc: 0.8702 - val_loss: 0.3187 - val_acc: 0.8875\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.3502 - acc: 0.8709 - val_loss: 0.3079 - val_acc: 0.8920\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.3504 - acc: 0.8704 - val_loss: 0.3096 - val_acc: 0.8886\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.3504 - acc: 0.8724 - val_loss: 0.3057 - val_acc: 0.8879\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.3490 - acc: 0.8727 - val_loss: 0.2963 - val_acc: 0.8942\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.3450 - acc: 0.8727 - val_loss: 0.2950 - val_acc: 0.8945\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.3457 - acc: 0.8732 - val_loss: 0.3259 - val_acc: 0.8837\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.3413 - acc: 0.8751 - val_loss: 0.2957 - val_acc: 0.8926\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.3398 - acc: 0.8765 - val_loss: 0.3043 - val_acc: 0.8892\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.3429 - acc: 0.8734 - val_loss: 0.3094 - val_acc: 0.8875\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.3395 - acc: 0.8752 - val_loss: 0.3081 - val_acc: 0.8874\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.3365 - acc: 0.8765 - val_loss: 0.3042 - val_acc: 0.8926\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.3355 - acc: 0.8771 - val_loss: 0.2992 - val_acc: 0.8922\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.3367 - acc: 0.8776 - val_loss: 0.3181 - val_acc: 0.8846\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.3333 - acc: 0.8775 - val_loss: 0.3194 - val_acc: 0.8814\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.3335 - acc: 0.8784 - val_loss: 0.3009 - val_acc: 0.8921\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.3306 - acc: 0.8801 - val_loss: 0.3072 - val_acc: 0.8881\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.3279 - acc: 0.8794 - val_loss: 0.2994 - val_acc: 0.8916\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.3294 - acc: 0.8789 - val_loss: 0.2980 - val_acc: 0.8949\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.3279 - acc: 0.8806 - val_loss: 0.2901 - val_acc: 0.8992\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.3266 - acc: 0.8797 - val_loss: 0.3105 - val_acc: 0.8933\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.3255 - acc: 0.8801 - val_loss: 0.3008 - val_acc: 0.8924\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.3234 - acc: 0.8812 - val_loss: 0.2953 - val_acc: 0.8943\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd357fa15c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwQQW5iOJjwq",
        "colab_type": "text"
      },
      "source": [
        "###  Report the final train and validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1SrtBEPJjwq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2fb3bed7-48b4-48f8-af39-f5448ab3e4bc"
      },
      "source": [
        "scores = model.evaluate(TestX, y_test)\n",
        "scores[1]*100"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 80us/sample - loss: 0.2950 - acc: 0.8943\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "89.42999839782715"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KXqmUDW2rM1",
        "colab_type": "text"
      },
      "source": [
        "## **DATA AUGMENTATION ON CIFAR10 DATASET**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mja6OgQ3L18",
        "colab_type": "text"
      },
      "source": [
        "One of the best ways to improve the performance of a Deep Learning model is to add more data to the training set. Aside from gathering more instances from the wild that are representative of the distinction task, we want to develop a set of methods that enhance the data we already have. There are many ways to augment existing datasets and produce more robust models. In the image domain, these are done to utilize the full power of the convolutional neural network, which is able to capture translational invariance. This translational invariance is what makes image recognition such a difficult task in the first place. You want the dataset to be representative of the many different positions, angles, lightings, and miscellaneous distortions that are of interest to the vision task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HzVTPUM3WZJ",
        "colab_type": "text"
      },
      "source": [
        "### **Import neessary libraries for data augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPM558TX4KMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6hicLwP4SqY",
        "colab_type": "text"
      },
      "source": [
        "### **Load CIFAR10 dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ1WzrXd4WNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 100\n",
        "data_augmentation = True\n",
        "num_predictions = 20\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'keras_cifar10_trained_model.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9Pht1ggHuiT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "c03bfcaf-7ab2-4969-cc0d-e7dd49fd81b7"
      },
      "source": [
        "# The data, split between train and test sets:\n",
        "(xtrain, ytrain), (xtest, ytest) = cifar10.load_data()\n",
        "print('x_train shape:', xtrain.shape)\n",
        "print(xtrain.shape[0], 'train samples')\n",
        "print(xtest.shape[0], 'test samples')"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n28ccU6Hp6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert class vectors to binary class matrices.\n",
        "ytrain = keras.utils.to_categorical(ytrain, num_classes)\n",
        "ytest = keras.utils.to_categorical(ytest, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ozo2GaS-dRMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain = xtrain.astype('float32')\n",
        "xtest = xtest.astype('float32')\n",
        "xtrain /= 255\n",
        "xtest /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN3vYYhK4W0u",
        "colab_type": "text"
      },
      "source": [
        "### **Create a data_gen funtion to genererator with image rotation,shifting image horizontally and vertically with random flip horizontally.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJbekTKi4cmM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_generator(df, batchsize=32, train_mode=True):   \n",
        "    \n",
        "    img_generator= tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=20,\n",
        "                                                                   width_shift_range=0.2,\n",
        "                                                                   height_shift_range=0.2,\n",
        "                                                                   horizontal_flip=True)\n",
        "    img_generator.fit(xtrain)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-SLtUhC4dK2",
        "colab_type": "text"
      },
      "source": [
        "### **Prepare/fit the generator.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vqltSZWhw68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu'))\n",
        "model.add(tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "#Output layer\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51o4S4gfhzqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZ8kB150eanB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "eab596d1-0dbc-426e-94e5-1e11a24e5b93"
      },
      "source": [
        "model.fit_generator(img_generator.flow(xtrain, ytrain, batch_size = 32), \n",
        "                          epochs=10,\n",
        "                          steps_per_epoch= xtrain.shape[0]//batchsize,\n",
        "                          validation_data=(xtest,ytest),\n",
        "                          validation_steps = xtest.shape[0]//batchsize)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1562/1562 [==============================] - 26s 16ms/step - loss: 1.7084 - acc: 0.3165 - val_loss: 1.3257 - val_acc: 0.5238\n",
            "Epoch 2/10\n",
            "1562/1562 [==============================] - 25s 16ms/step - loss: 1.4670 - acc: 0.4588 - val_loss: 1.1965 - val_acc: 0.5669\n",
            "Epoch 3/10\n",
            "1562/1562 [==============================] - 25s 16ms/step - loss: 1.3842 - acc: 0.4958 - val_loss: 1.2003 - val_acc: 0.5661\n",
            "Epoch 4/10\n",
            "1562/1562 [==============================] - 25s 16ms/step - loss: 1.3351 - acc: 0.5186 - val_loss: 1.1098 - val_acc: 0.5994\n",
            "Epoch 5/10\n",
            "1562/1562 [==============================] - 25s 16ms/step - loss: 1.2927 - acc: 0.5370 - val_loss: 1.1044 - val_acc: 0.6070\n",
            "Epoch 6/10\n",
            "1562/1562 [==============================] - 25s 16ms/step - loss: 1.2637 - acc: 0.5507 - val_loss: 1.0984 - val_acc: 0.6160\n",
            "Epoch 7/10\n",
            "1562/1562 [==============================] - 25s 16ms/step - loss: 1.2372 - acc: 0.5533 - val_loss: 1.0546 - val_acc: 0.6296\n",
            "Epoch 8/10\n",
            "1562/1562 [==============================] - 25s 16ms/step - loss: 1.2207 - acc: 0.5641 - val_loss: 1.0165 - val_acc: 0.6400\n",
            "Epoch 9/10\n",
            "1562/1562 [==============================] - 25s 16ms/step - loss: 1.2029 - acc: 0.5749 - val_loss: 1.0287 - val_acc: 0.6349\n",
            "Epoch 10/10\n",
            "1562/1562 [==============================] - 25s 16ms/step - loss: 1.1850 - acc: 0.5763 - val_loss: 1.0702 - val_acc: 0.6360\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd349741d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYyF-P8O4jQ8",
        "colab_type": "text"
      },
      "source": [
        "### **Generate 5 images for 1 of the image of CIFAR10 train dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cUCZm_deVcc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "0928991c-e7e1-40a5-c974-959b61a432be"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "gen = datagen.flow(x_train[0:1], batch_size=1)\n",
        "for i in range(1, 6):\n",
        "    plt.subplot(1,5,i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(gen.next().squeeze(), cmap='gray')\n",
        "    plt.plot()\n",
        "plt.show()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAABcCAYAAAB3AO7GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ns4AbM2bM2A01s4AbM2bM2A21/w+4sOQZ01hmugAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}